{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import bio_helper\n",
    "from tools import *\n",
    "from fdr_test import fixed_features\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pept3 import model\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_psmid_table(table_file, psmid):\n",
    "    table = pd.read_csv(table_file, sep='\\t')\n",
    "    return table[table['SpecId'].apply(lambda x: x in psmid)]\n",
    "\n",
    "def shared_psmid(nf_psms, f_psms, threshold=0.01):\n",
    "    nf = pd.read_csv(nf_psms, sep='\\t')\n",
    "    f = pd.read_csv(f_psms, sep='\\t')\n",
    "    nf_psmid = set([\"-\".join(i.split('-')[:6]) for i in nf[nf['q-value'] <= threshold]['PSMId']])\n",
    "    f_psmid = set([\"-\".join(i.split('-')[:6]) for i in f[f['q-value'] <= threshold]['PSMId']])\n",
    "    return nf_psmid-f_psmid, nf_psmid.intersection(f_psmid), f_psmid - nf_psmid\n",
    "\n",
    "def shared_peptide(nf_psms, f_psms, threshold=0.01):\n",
    "    nf = pd.read_csv(nf_psms, sep='\\t')\n",
    "    f = pd.read_csv(f_psms, sep='\\t')\n",
    "    nf_psmid = set(nf[nf['q-value'] <= threshold]['peptide'].apply(lambda x: x.strip(\"_\").strip(\".\")))\n",
    "    f_psmid = set(f[f['q-value'] <= threshold]['peptide'].apply(lambda x: x.strip(\"_\").strip(\".\")))\n",
    "    pep_psmid = {i:j for i,j in zip(f[f['q-value'] <= threshold]['peptide'].apply(lambda x: x.strip(\"_\").strip(\".\")), f[f['q-value'] <= threshold]['PSMId'])}\n",
    "    return nf_psmid-f_psmid, nf_psmid.intersection(f_psmid), f_psmid - nf_psmid, pep_psmid\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_field = ['collision_energy_aligned_normed', 'sequence_integer', 'precursor_charge_onehot', 'intensities_raw', 'score']\n",
    "def filter_HLA(file):\n",
    "    data = h5py.File(file, 'r')\n",
    "    index = []\n",
    "    rawfiles = np.array(data['rawfile']).astype(\"str\")\n",
    "    for i in rawfiles:\n",
    "        index.append(\"HLA\" in i)\n",
    "    index = np.array(index)\n",
    "    re_data = {}\n",
    "    for k in want_field:\n",
    "        re_data[k] = np.array(data[k])[index]\n",
    "    return re_data\n",
    "\n",
    "temp_DATA = []\n",
    "temp_DATA.append(filter_HLA('/data/yejb/prosit/figs/boosting/train/prediction_hcd_train.hdf5'))\n",
    "temp_DATA.append(filter_HLA('/data/yejb/prosit/figs/boosting/train/prediction_hcd_val.hdf5'))\n",
    "temp_DATA.append(filter_HLA('/data/yejb/prosit/figs/boosting/train/prediction_hcd_ho.hdf5'))\n",
    "\n",
    "DATA = {}\n",
    "for k in want_field:\n",
    "    DATA[k] = np.concatenate([temp[k] for temp in temp_DATA])\n",
    "del temp_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axis_style(ax, labels):\n",
    "    ax.xaxis.set_tick_params(direction='out')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1),)\n",
    "    ax.set_xticklabels(labels, fontsize=15)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    # ax.set_xlabel('Sample name')\n",
    "\n",
    "def plot_half_violin(data_dict : dict):\n",
    "    fig, ax = plt.subplots(figsize=(4, 6), dpi=100)\n",
    "    labels = list(data_dict)\n",
    "\n",
    "    no_finetuned = [v[0] for v in data_dict.values()] \n",
    "    finetuned = [v[1] for v in data_dict.values()] \n",
    "\n",
    "    mins = [min(np.min(i), np.min(j)) for i, j in zip(no_finetuned, finetuned)]\n",
    "    maxs = [max(np.max(i), np.max(j)) for i, j in zip(no_finetuned, finetuned)]\n",
    "\n",
    "    plot1 = ax.violinplot(no_finetuned, showmeans=False, showextrema=False, showmedians=False)\n",
    "    for b in plot1['bodies']:\n",
    "        # get the center\n",
    "        m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "        # modify the paths to not go further right than the center\n",
    "        b.get_paths()[0].vertices[:, 0] = np.clip(b.get_paths()[0].vertices[:, 0], -np.inf, m)\n",
    "        b.set_edgecolor('lightgray')\n",
    "        # b.set_edgewidth(2)\n",
    "    plot2 = ax.violinplot(finetuned, showmeans=False, showextrema=False, showmedians=False)\n",
    "    for b in plot2['bodies']:\n",
    "        # get the center\n",
    "        m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "        # modify the paths to not go further left than the center\n",
    "        b.get_paths()[0].vertices[:, 0] = np.clip(b.get_paths()[0].vertices[:, 0], m, np.inf)\n",
    "        # b.set_color('b')\n",
    "        b.set_edgecolor('lightgray')\n",
    "        # b.set_edgewidth(2)\n",
    "    for i in range(len(labels)):\n",
    "        ax.text(i+1-0.2, 0.4, f\"n={len(finetuned[i])}\", fontsize=8, rotation=90, va='center')\n",
    "    # ax.vlines([i+1 for i in range(len(labels))], mins, maxs, color='gray', linestyles='--', lw=1)\n",
    "    \n",
    "    x_axises = np.array([i+1 for i in range(len(labels))])\n",
    "    nf_sa_mean = [np.mean(i) for i in no_finetuned]\n",
    "    f_sa_mean = [np.mean(i) for i in finetuned]\n",
    "\n",
    "    ax.hlines(nf_sa_mean, x_axises-0.2, x_axises, color='slateblue', linestyles='-', lw=1)\n",
    "    ax.hlines(f_sa_mean, x_axises, x_axises+0.2, color='orange', linestyles='-', lw=1)\n",
    "    ax.legend([plot1['bodies'][0],plot2['bodies'][0]],['No fine-tuned', 'Fine-tuned'], loc='lower right', frameon=False)\n",
    "    set_axis_style(ax, labels)\n",
    "    ax.set_ylabel(\"Spectral Angle\", fontsize=15)\n",
    "    return fig, ax\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psmid2charge(psms):\n",
    "    charges = [int(i.split(\"-\")[5]) for i in psms]\n",
    "    return charges\n",
    "\n",
    "def seq2int(S):\n",
    "    len = S.shape[-1]\n",
    "    base = 22\n",
    "    base_p = np.array([\n",
    "        [base**i if i < len//2 else 0 for i in range(len)],\n",
    "        [base**(i-len//2) if i >= len//2 else 0 for i in range(len)]], dtype='int64')\n",
    "    re = S@base_p.T\n",
    "    return re\n",
    "INT_S = seq2int(DATA['sequence_integer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4027530, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INT_S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_syn_spectrum(peptides, charges, Global_S):\n",
    "    from time import time\n",
    "    start = time()\n",
    "    seqs = [bio_helper.peptide_to_inter(i) for i in peptides]\n",
    "    seqs = np.concatenate(seqs)\n",
    "\n",
    "    charges = np.array(charges).squeeze() - 1\n",
    "\n",
    "    found = 0\n",
    "    data_charges = np.argmax(DATA['precursor_charge_onehot'], axis=1)\n",
    "    Global_S = Global_S.squeeze()\n",
    "    pre_data = {}\n",
    "    pre_data['peptides'] = []\n",
    "    int_seqs = seq2int(seqs).squeeze()\n",
    "    G1 = Global_S[:, 0]\n",
    "    G2 = Global_S[:, 1]\n",
    "    for count, (seq, c) in enumerate(zip(int_seqs, charges)):\n",
    "        sys.stdout.write(f\"Found {found}/{count+1}\\r\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        _p1 = (G1 == seq[0])\n",
    "        _p2 = (G2 == seq[1])\n",
    "        p_index = np.logical_and(_p1, _p2)\n",
    "        \n",
    "        # _p_index = np.all(DATA['sequence_integer'] == seqs[count], axis=1)\n",
    "        # assert np.all(p_index == _p_index)\n",
    "        c_index = (data_charges == c)\n",
    "\n",
    "        index = np.logical_and(p_index.reshape(-1), c_index.reshape(-1))\n",
    "\n",
    "        if np.sum(index) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            found += 1\n",
    "        arg_select = np.argmax(DATA['score'][index])\n",
    "        pre_data['peptides'].append(peptides[count])\n",
    "        for k in want_field:\n",
    "            pre_item = DATA[k][index][arg_select].reshape(1, -1)\n",
    "            if k in pre_data:\n",
    "                pre_data[k] = np.concatenate([pre_data[k], pre_item])\n",
    "            else:\n",
    "                pre_data[k] = pre_item\n",
    "    print()\n",
    "    return pre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "load from ../checkpoints/finetuned/HLA-I/Mel-3_HLA-I\n",
      "Search 1107\n",
      "Found 17/90\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57471/979641858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mpart_charges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsmid2charge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpep2psmid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhich_part\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mpre_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_syn_spectrum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_charges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_57471/2440162872.py\u001b[0m in \u001b[0;36mfind_syn_spectrum\u001b[0;34m(peptides, charges, Global_S)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_p1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mG1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0m_p2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mG2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mp_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_p1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_p2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frag_model = \"prosit_l1\"\n",
    "if frag_model == \"prosit_cid\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_cid_frag_PrositFrag-512.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "elif frag_model == \"prosit_hcd\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_hcd_frag_PrositFrag-512.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "elif frag_model == \"prosit_l1\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_frag_l1_PrositFrag-1024.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "    \n",
    "def pick_finetuned_model(path):\n",
    "    run_model1 = model.PrositFrag()\n",
    "    run_model2 = model.PrositFrag()\n",
    "    weights = torch.load(os.path.join(path, f\"{frag_model}.pth\"), map_location=\"cpu\")\n",
    "    run_model1.load_state_dict(weights[0])\n",
    "    run_model2.load_state_dict(weights[1])\n",
    "    run_model1 = run_model1.eval()\n",
    "    run_model2 = run_model2.eval()\n",
    "    return run_model1, run_model2\n",
    "\n",
    "def track_raw_spectrum(rawfile, scannum, intensities_raw, psmids):\n",
    "    intens = []\n",
    "    for psmid in psmids:\n",
    "        packs = psmid.split(\"-\")\n",
    "        charge = int(packs[-1])\n",
    "        pep = packs[-2]\n",
    "        sn = int(packs[-3])\n",
    "        rf = '-'.join(packs[:-3])\n",
    "        \n",
    "        index = np.logical_and((rawfile == rf.encode()).reshape(-1), (scannum == sn).reshape(-1))\n",
    "        intens.append(intensities_raw[index])\n",
    "    return np.concatenate(intens)    \n",
    "\n",
    "nces = 32\n",
    "hla_mel = pd.read_csv(\"./data/HLA_Mel.csv\")\n",
    "hla_mel = hla_mel[hla_mel['Experiment'].apply(\n",
    "    lambda x: x.endswith(\"HLA-I\"))]\n",
    "Mels = hla_mel['Experiment'].unique()\n",
    "set_threshold = 0.1\n",
    "plt.ion()\n",
    "for which in Mels:\n",
    "# for which in ['Mel-12_HLA-I']:\n",
    "    print(\"-------------------------------\")\n",
    "    f_model_path = os.path.join('../checkpoints/finetuned/HLA-I', which)\n",
    "    print(\"load from\", f_model_path)\n",
    "    f_model1, f_model2 = pick_finetuned_model(f_model_path)\n",
    "    f_tab = f\"/data/yejb/prosit/figs/boosting/figs/Figure_5_HLA_1/{frag_model}/percolator_hdf5_Mels_{set_threshold}/{which}\"\n",
    "    nf_tab = f\"/data/yejb/prosit/figs/boosting/figs/Figure_5_HLA_1/forPride/rescoring_for_paper_2/Mels/{which}/percolator\"\n",
    "    f_peps = os.path.join(f_tab, \"prosit_target.peptides\")\n",
    "    nf_peps = os.path.join(nf_tab, \"prosit_target.peptides\")\n",
    "    hdf5_file = os.path.join(nf_tab, \"../data.hdf5\")\n",
    "    \n",
    "    hdf5_data = h5py.File(hdf5_file, \"r\")\n",
    "    hdf5_rawfile = np.array(hdf5_data['rawfile'])\n",
    "    hdf5_scannum = np.array(hdf5_data['scan_number'])\n",
    "    hdf5_intens = np.array(hdf5_data['intensities_raw'])\n",
    "    \n",
    "    L, S, G, pep2psmid = shared_peptide(nf_peps, f_peps)\n",
    "    # print(list(pep2psmid.values())[:10])\n",
    "    # break\n",
    "    which_part = list(G)\n",
    "    print(\"Search\", len(which_part))\n",
    "    \n",
    "    part_charges = psmid2charge([pep2psmid[i] for i in which_part])\n",
    "    pre_data = find_syn_spectrum(which_part, part_charges, INT_S)\n",
    "    break\n",
    "    \n",
    "    candi_peps = pre_data['peptides']\n",
    "    raw_intens = track_raw_spectrum(hdf5_rawfile, hdf5_scannum, hdf5_intens, [pep2psmid[i] for i in candi_peps])\n",
    "    # print(raw_intens.shape)\n",
    "    # print({k:v.shape for k, v in pre_data.items() if isinstance(v, np.ndarray)})\n",
    "        \n",
    "    frag_msms = pre_data['intensities_raw']\n",
    "    # print(pre_data['collision_energy_aligned_normed'].min(), pre_data['collision_energy_aligned_normed'].max())\n",
    "    data_nce_cand = [\n",
    "        pre_data['sequence_integer'].astype('int'),\n",
    "        # pre_data['collision_energy_aligned_normed'],\n",
    "        np.ones((len(pre_data['sequence_integer']), ), dtype=int) * nces / 100.0,\n",
    "        pre_data['precursor_charge_onehot'].astype(\"int\")\n",
    "    ]\n",
    "    prosit_sa, prosit_inten = get_sa_all(run_model, data_nce_cand, frag_msms, pearson=(frag_model == 'pdeep2'))\n",
    "    prosit_sa = prosit_sa.cpu().numpy()\n",
    "    prosit_inten = prosit_inten.cpu().numpy()\n",
    "\n",
    "    # f_sas = []\n",
    "    # f_spectra = []\n",
    "    # for ft_model in [f_model1, f_model2]:\n",
    "    #     finetune_prosit_sa, finetune_prosit_inten = get_sa_all(\n",
    "    #         ft_model, data_nce_cand, frag_msms, pearson=(frag_model == 'pdeep2'))\n",
    "    #     finetune_prosit_sa = finetune_prosit_sa.cpu().numpy()\n",
    "    #     finetune_prosit_inten = finetune_prosit_inten.cpu().numpy()\n",
    "    #     f_sas.append(finetune_prosit_sa)\n",
    "    #     f_spectra.append(finetune_prosit_inten)\n",
    "\n",
    "    # finetune_prosit_sa = (f_sas[0] + f_sas[1])/2\n",
    "    # # finetune_prosit_sa = f_sas[0]\n",
    "    # finetune_prosit_inten = (f_spectra[0] + f_spectra[1])/2\n",
    "    sa_data = {\n",
    "        'sequence_integer': torch.from_numpy(data_nce_cand[0]),\n",
    "        'precursor_charge_onehot': torch.from_numpy(data_nce_cand[2]),\n",
    "    }\n",
    "    raw_sa, _ = helper.predict_sa(torch.from_numpy(frag_msms), torch.from_numpy(raw_intens), sa_data)\n",
    "    raw_sa = raw_sa.cpu().numpy()\n",
    "\n",
    "    data_dict = {which: (prosit_sa, raw_sa)}\n",
    "    plt.show()\n",
    "    plot_half_violin(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_model = \"prosit_l1\"\n",
    "if frag_model == \"prosit_cid\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_cid_frag_PrositFrag-512.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "elif frag_model == \"prosit_hcd\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_hcd_frag_PrositFrag-512.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "elif frag_model == \"prosit_l1\":\n",
    "    run_model = model.PrositFrag()\n",
    "    run_model.load_state_dict(torch.load(\n",
    "        \"../checkpoints/frag_boosting/best_frag_l1_PrositFrag-1024.pth\", map_location=\"cpu\"))\n",
    "    run_model = run_model.eval()\n",
    "    \n",
    "def pick_finetuned_model(path):\n",
    "    run_model1 = model.PrositFrag()\n",
    "    run_model2 = model.PrositFrag()\n",
    "    weights = torch.load(os.path.join(path, f\"{frag_model}.pth\"), map_location=\"cpu\")\n",
    "    run_model1.load_state_dict(weights[0])\n",
    "    run_model2.load_state_dict(weights[1])\n",
    "    run_model1 = run_model1.eval()\n",
    "    run_model2 = run_model2.eval()\n",
    "    return run_model1, run_model2\n",
    "\n",
    "nces = 32\n",
    "hla_mel = pd.read_csv(\"./data/HLA_Mel.csv\")\n",
    "hla_mel = hla_mel[hla_mel['Experiment'].apply(\n",
    "    lambda x: x.endswith(\"HLA-I\"))]\n",
    "Mels = hla_mel['Experiment'].unique()\n",
    "set_threshold = 0.1\n",
    "for which in Mels:\n",
    "    print(\"-------------------------------\")\n",
    "    f_model_path = os.path.join('../checkpoints/finetuned/HLA-I', which)\n",
    "    print(\"load from\", f_model_path)\n",
    "    f_model1, f_model2 = pick_finetuned_model(f_model_path)\n",
    "    f_tab = f\"/data/yejb/prosit/figs/boosting/figs/Figure_5_HLA_1/{frag_model}/percolator_hdf5_Mels_{set_threshold}/{which}\"\n",
    "    nf_tab = f\"/data/yejb/prosit/figs/boosting/figs/Figure_5_HLA_1/forPride/rescoring_for_paper_2/Mels/{which}/percolator\"\n",
    "    f_peps = os.path.join(f_tab, \"prosit_target.peptides\")\n",
    "    nf_peps = os.path.join(nf_tab, \"prosit_target.peptides\")\n",
    "    hfd5_file = os.path.join(nf_tab, \"../data.hdf5\")\n",
    "    L, S, G, pep2psmid = shared_peptide(nf_peps, f_peps)\n",
    "    \n",
    "    which_part = list(G)\n",
    "    print(\"Search\", len(which_part))\n",
    "    part_charges = psmid2charge([pep2psmid[i] for i in which_part])\n",
    "    pre_data = find_syn_spectrum(which_part, part_charges)\n",
    "        \n",
    "    frag_msms = pre_data['intensities_raw']\n",
    "    print(pre_data['collision_energy_aligned_normed'].min(), pre_data['collision_energy_aligned_normed'].max())\n",
    "    print({k:v.shape for k, v in pre_data.items()})\n",
    "    data_nce_cand = [\n",
    "        pre_data['sequence_integer'].astype('int'),\n",
    "        # pre_data['collision_energy_aligned_normed'],\n",
    "        np.ones((len(pre_data['sequence_integer']), ), dtype=int) * nces / 100.0,\n",
    "        pre_data['precursor_charge_onehot'].astype(\"int\")\n",
    "    ]\n",
    "    prosit_sa, prosit_inten = get_sa_all(run_model, data_nce_cand, frag_msms, pearson=(frag_model == 'pdeep2'))\n",
    "    prosit_sa = prosit_sa.cpu().numpy()\n",
    "    prosit_inten = prosit_inten.cpu().numpy()\n",
    "\n",
    "    f_sas = []\n",
    "    f_spectra = []\n",
    "    for ft_model in [f_model1, f_model2]:\n",
    "        finetune_prosit_sa, finetune_prosit_inten = get_sa_all(\n",
    "            ft_model, data_nce_cand, frag_msms, pearson=(frag_model == 'pdeep2'))\n",
    "        finetune_prosit_sa = finetune_prosit_sa.cpu().numpy()\n",
    "        finetune_prosit_inten = finetune_prosit_inten.cpu().numpy()\n",
    "        f_sas.append(finetune_prosit_sa)\n",
    "        f_spectra.append(finetune_prosit_inten)\n",
    "\n",
    "    finetune_prosit_sa = (f_sas[0] + f_sas[1])/2\n",
    "    # finetune_prosit_sa = f_sas[0]\n",
    "    finetune_prosit_inten = (f_spectra[0] + f_spectra[1])/2\n",
    "\n",
    "    print(np.median(prosit_sa), np.median(finetune_prosit_sa))\n",
    "    print(np.mean(prosit_sa), np.mean(finetune_prosit_sa))\n",
    "    print(np.max(prosit_sa), np.max(finetune_prosit_sa))\n",
    "    print(np.min(prosit_sa), np.min(finetune_prosit_sa))\n",
    "\n",
    "    data_dict = {which: (prosit_sa, finetune_prosit_sa)}\n",
    "    plot_half_violin(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17465660725f2b6bdd0101ccb038f8fe4c98405cd7a343be234717463386f391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
